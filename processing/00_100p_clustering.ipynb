{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO, AlignIO, Seq\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "#### Creating csv file from the data in Jaffe et al. and cleaning sequence ID from \":\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is to remove places with more than one `_` from the ids because after moving to iTOL this will be a problem. We do this for the files `jaffe_et_al_2018_rubisco_superfamilies.faa`, `RuBisCO.300-700.faa`, and `milo_synthetized_rubisco.faa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for record in SeqIO.parse('../data/jaffe_et_al_2018_rubisco_superfamilies.faa', \"fasta\"):\n",
    "    record.description = record.description.split(':')[0]\n",
    "    record.id = record.id.split(':')[0]\n",
    "    record.name = record.name.split(':')[0]\n",
    "    sequences.append(record)\n",
    "!mkdir -p ../output/00_100p_tree\n",
    "with open(r\"../output/00_100p_tree/jaffe_et_al_2018_rubisco_superfamilies_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for record in SeqIO.parse('../data/RuBisCO.300-700_20190429_processed.faa', \"fasta\"):\n",
    "    record.seq = record.seq.rstrip(chars='*')\n",
    "    sequences.append(record)\n",
    "        \n",
    "with open(r\"../output/00_100p_tree/RuBisCO.300-700_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge fasta files and cluster sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ../data/milo_synthetized_rubisco.faa ../data/RuBisCO.300-700.faa ../data/flamholz_et_al_2019_kinetically_characterized.faa ../data/erb_et_al_2012_rubisco_superfamilies.faa > ../data/merged_data.faa\n",
    "!cat ../data/milo_synthetized_rubisco.faa ../output/00_100p_tree/RuBisCO.300-700_clean.faa ../data/flamholz_et_al_2019_kinetically_characterized.faa ../output/00_100p_tree/jaffe_et_al_2018_rubisco_superfamilies_clean.faa > ../output/00_100p_tree/merged_data.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove sequences with ambiguous calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ['A','R','N','D','C','G','Q','E','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "ambiguous_aa = ['B','Z','X','J']\n",
    "canon = []\n",
    "for record in SeqIO.parse('../output/00_100p_tree/merged_data.faa', \"fasta\"):\n",
    "    no_of_aa = np.array([x in ambiguous_aa for x in record.seq]).sum()\n",
    "    if no_of_aa == 0:\n",
    "        canon.append(record)\n",
    "\n",
    "with open(r\"../output/00_100p_tree/merged_data_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(canon, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster sequences based on 100 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (16.3Gb total), 8 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: yinonmoise.baron@weizmann.ac.il\n",
      "\n",
      "00:01 78Mb    100.0% Reading ../output/00_100p_tree/merged_data_clean.faa\n",
      "00:01 118Mb   100.0% DF\n",
      "00:01 120Mb  57626 seqs, 56166 uniques, 55141 singletons (98.2%)\n",
      "00:01 120Mb  Min size 1, median 1, max 48, avg 1.03\n",
      "00:01 127Mb   100.0% DB\n",
      "02:42 316Mb   100.0% 40945 clusters, max size 72, avg 1.4\n",
      "                                                         \n",
      "      Seqs  56166 (56.2k)\n",
      "  Clusters  40945 (40.9k)\n",
      "  Max size  72\n",
      "  Avg size  1.4\n",
      "  Min size  1\n",
      "Singletons  32331 (32.3k), 57.6% of seqs, 79.0% of clusters\n",
      "   Max mem  316Mb\n",
      "      Time  02:41\n",
      "Throughput  348.9 seqs/sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!../bin/usearch11.0.667_i86linux32 -cluster_fast ../output/00_100p_tree/merged_data_clean.faa -id 1 -uc ../output/00_100p_tree/uclust_all_1.uc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine cluster centroids to include synthesized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Type','Cluster','Size','%Id','Strand','Qlo','Tlo','Alignment','Query','Target']\n",
    "uclust = pd.read_csv('../output/00_100p_tree/uclust_all_1.uc', sep='\\t', names=header, index_col=False)\n",
    "uclust.loc[uclust['Target'] =='*','Target'] = uclust.loc[uclust['Target'] =='*','Query']\n",
    "\n",
    "# Find synthetized sequences that are not centroids and replace them as centroids\n",
    "synth_clusters = uclust[uclust['Query'].str.startswith('RBC') & ~uclust['Target'].str.startswith('RBC')]\n",
    "for i in synth_clusters.iterrows():\n",
    "    uclust.loc[uclust.Target== i[1].Target,'Target'] = i[1].Query\n",
    "\n",
    "centroids = uclust[uclust['Type']=='C']\n",
    "c_list = centroids.iloc[:,8].values\n",
    "c_list = [c.split(\" \")[0] for c in c_list]\n",
    "\n",
    "sequences = []\n",
    "for record in SeqIO.parse('../output/00_100p_tree/RuBisCO.300-700_clean.faa', \"fasta\"):\n",
    "    if record.id in c_list:\n",
    "        sequences.append(record)\n",
    "\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "for i,record in enumerate(sequences):\n",
    "    if not record.id in seq2: \n",
    "        seq2.append(record.id)\n",
    "        seq3.append(record)\n",
    "with open('../output/00_100p_tree/uclust_all_1.faa', \"w\") as output_handle:\n",
    "    SeqIO.write(seq3, output_handle, \"fasta\")\n",
    "\n",
    "uclust.to_csv('../output/00_100p_tree/uclust_all_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt type legend to the new centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = pd.read_csv('../data/jaffe_et_al_2018_rubisco_types.csv')\n",
    "cluster_labels = uclust.merge(type_labels,left_on='Query',right_on='ID')[['Target','Organism','type']]\n",
    "cluster_labels.columns = ['ID','Organism','type']\n",
    "cluster_labels.to_csv('../output/00_100p_tree/uclust_all_1_rubisco_types.csv',index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
