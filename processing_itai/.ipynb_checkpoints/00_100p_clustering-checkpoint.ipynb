{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO, AlignIO, Seq\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is to remove places with more than one `_` from the ids because after moving to iTOL this will be a problem. We do this for the file  `RuBisCO.300-700.faa` and save it with the suffix 'processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating csv file from the data in Jaffe et al. and cleaning sequence ID from \":\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for record in SeqIO.parse('../data/jaffe_et_al_2018_rubisco_superfamilies.faa', \"fasta\"):\n",
    "    record.description = record.description.split(':')[0]\n",
    "    record.id = record.id.split(':')[0]\n",
    "    record.name = record.name.split(':')[0]\n",
    "    sequences.append(record)\n",
    "!mkdir -p ../output_itai/00_100p_tree\n",
    "with open(r\"../output_itai/00_100p_tree/jaffe_et_al_2018_rubisco_superfamilies_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing * from the end of the fasta file RuBisCO.300-700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for record in SeqIO.parse('../data/RuBisCO.ok_processed.faa', \"fasta\"):\n",
    "    record.seq = record.seq.rstrip(chars='*')\n",
    "    sequences.append(record)\n",
    "        \n",
    "with open(r\"../output_itai/00_100p_tree/RuBisCO.ok_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge fasta files and cluster sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ../data/milo_synthetized_rubisco.faa ../data/RuBisCO.300-700.faa ../data/flamholz_et_al_2019_kinetically_characterized.faa ../data/erb_et_al_2012_rubisco_superfamilies.faa > ../data/merged_data.faa\n",
    "!cat ../data/milo_synthetized_rubisco.faa ../output_itai/00_100p_tree/RuBisCO.ok_clean.faa ../data/flamholz_et_al_2019_kinetically_characterized.faa ../output_itai/00_100p_tree/jaffe_et_al_2018_rubisco_superfamilies_clean.faa > ../output_itai/00_100p_tree/merged_data.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove sequences with ambiguous calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ['A','R','N','D','C','G','Q','E','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "ambiguous_aa = ['B','Z','X','J']\n",
    "canon = []\n",
    "for record in SeqIO.parse('../output_itai/00_100p_tree/merged_data.faa', \"fasta\"):\n",
    "    no_of_aa = np.array([x in ambiguous_aa for x in record.seq]).sum()\n",
    "    if no_of_aa == 0:\n",
    "        canon.append(record)\n",
    "\n",
    "with open(r\"../output_itai/00_100p_tree/merged_data_clean.faa\", \"w\") as output_handle:\n",
    "    SeqIO.write(canon, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster sequences based on 100 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usearch v11.0.667_i86linux32, 4.0Gb RAM (16.3Gb total), 8 cores\n",
      "(C) Copyright 2013-18 Robert C. Edgar, all rights reserved.\n",
      "https://drive5.com/usearch\n",
      "\n",
      "License: yinonmoise.baron@weizmann.ac.il\n",
      "\n",
      "00:01 88Mb    100.0% Reading ../output_itai/00_100p_tree/merged_data_clean.faa\n",
      "00:01 131Mb   100.0% DF\n",
      "00:01 132Mb  75771 seqs, 74317 uniques, 73300 singletons (98.6%)\n",
      "00:01 132Mb  Min size 1, median 1, max 48, avg 1.02\n",
      "00:01 143Mb   100.0% DB\n",
      "03:47 343Mb   100.0% 50020 clusters, max size 86, avg 1.5\n",
      "                                                         \n",
      "      Seqs  74317 (74.3k)\n",
      "  Clusters  50020 (50.0k)\n",
      "  Max size  86\n",
      "  Avg size  1.5\n",
      "  Min size  1\n",
      "Singletons  38551 (38.6k), 51.9% of seqs, 77.1% of clusters\n",
      "   Max mem  343Mb\n",
      "      Time  03:46\n",
      "Throughput  328.8 seqs/sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!../bin/usearch11.0.667_i86linux32 -cluster_fast ../output_itai/00_100p_tree/merged_data_clean.faa -id 1 -uc ../output_itai/00_100p_tree/uclust_all_1.uc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine cluster centroids to include synthesized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Type','Cluster','Size','%Id','Strand','Qlo','Tlo','Alignment','Query','Target']\n",
    "uclust = pd.read_csv('../output_itai/00_100p_tree/uclust_all_1.uc', sep='\\t', names=header, index_col=False)\n",
    "uclust = uclust[uclust['Type'] !='S']\n",
    "uclust.loc[uclust['Target'] =='*','Target'] = uclust.loc[uclust['Target'] =='*','Query']\n",
    "\n",
    "# Find synthetized sequences that are not centroids and replace them as centroids\n",
    "synth_clusters = uclust[uclust['Query'].str.startswith('RBC') & ~uclust['Target'].str.startswith('RBC')]\n",
    "for i in synth_clusters.iterrows():\n",
    "    uclust.loc[uclust.Target== i[1].Target,'Target'] = i[1].Query\n",
    "\n",
    "centroids = uclust[uclust['Type']=='C']\n",
    "c_list = centroids.Target.values\n",
    "c_list = [c.split(\" \")[0] for c in c_list]\n",
    "\n",
    "sequences = []\n",
    "for record in SeqIO.parse('../output_itai/00_100p_tree/merged_data_clean.faa', \"fasta\"):\n",
    "    if record.id in c_list:\n",
    "        sequences.append(record)\n",
    "\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "for i,record in enumerate(sequences):\n",
    "    if not record.id in seq2: \n",
    "        seq2.append(record.id)\n",
    "        seq3.append(record)\n",
    "with open('../output_itai/00_100p_tree/uclust_all_1.faa', \"w\") as output_handle:\n",
    "    SeqIO.write(seq3, output_handle, \"fasta\")\n",
    "\n",
    "uclust.to_csv('../output_itai/00_100p_tree/uclust_all_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt type legend to the new centroids\n",
    "\n",
    "This will also throw some of the sequences in jaffe_2018 because of ambiguous amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = pd.read_csv('../data/jaffe_et_al_2018_rubisco_types_processed.csv')\n",
    "cluster_labels = uclust.merge(type_labels,left_on='Query',right_on='ID')[['Target','Organism','type']]\n",
    "cluster_labels.columns = ['ID','Organism','type']\n",
    "cluster_labels.to_csv('../output_itai/00_100p_tree/uclust_all_1_rubisco_types.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:10: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "uclust = pd.read_csv('../output/00_100p_tree/uclust_all_1.csv')\n",
    "# remove type IV rubisco of rubrum to avoid mischaracterization\n",
    "uclust = uclust[~uclust.Query.str.contains('499709017')]\n",
    "\n",
    "kin_data = pd.read_excel('../data/flamholz_et_al_kinetic_data.xlsx','kinetic_data')\n",
    "kin_data = kin_data[~kin_data.vC.isna()]\n",
    "species = kin_data['Unnamed: 0'].apply(lambda x: \" \".join(x.split(' ')[:2]))\n",
    "species = species.unique()\n",
    "kin_list = []\n",
    "for i in species:\n",
    "    # Specific species which have both type I/IIIb and type IV\n",
    "    if i == 'Rhodopseudomonas palustris':\n",
    "        kin_list.append(uclust[uclust.Query.str.contains('90104852')].Target.values[0])\n",
    "        continue\n",
    "    if i == 'Allochromatium vinosum':\n",
    "        kin_list.append(uclust[uclust.Query.str.contains('502735590')].Target.values[0])\n",
    "        continue\n",
    "    if i == 'Archaeoglobus fulgidus':\n",
    "        kin_list.append(uclust[uclust.Query.str.contains('973026383')].Target.values[0])\n",
    "        continue\n",
    "    if i == 'Acidithiobacillus ferrooxidans':\n",
    "        kin_list.append(uclust[uclust.Query.str.contains('501530536')].Target.values[0])\n",
    "        kin_list.append(uclust[uclust.Query.str.contains('1427065124')].Target.values[0])\n",
    "        continue        \n",
    "        \n",
    "    if len(uclust[uclust.Query.str.contains(i)].Target.unique()) != 0:\n",
    "        if len(uclust[uclust.Query.str.contains(i)].Target.unique()) > 1:\n",
    "            tmp = uclust[uclust.Query.str.contains(i)].Target.unique()\n",
    "            kin_list.append(tmp[np.argmax([len(x) for x in tmp])])\n",
    "        else:\n",
    "            kin_list.append(uclust[uclust.Query.str.contains(i)].Target.unique()[0])\n",
    "\n",
    "pd.DataFrame(kin_list,columns=['kinetic_ID']).to_csv('../output_itai/00_100p_tree/uclust_all_1_kinetic_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "synth_data = pd.DataFrame([x.description for x in SeqIO.parse('../data/milo_synthetized_rubisco.faa',format='fasta')])\n",
    "uclust.merge(synth_data,left_on='Query',right_on=0).Target.to_csv('../output_itai/00_100p_tree/synth_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
